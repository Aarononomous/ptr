{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Tree Readability\n",
    "\n",
    "This Jupyter notebook is for developing, explaining, and experimenting with parse tree readability, a measure of readability I'm developing based on the premises that word length and sentence length are not the most important qualities of a piece of text when it comes to determining the difficulty of understanding it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Imports\n",
    "\n",
    "We'll need several libraries for the corpora, for simple text analysis, and for parsing sentences.\n",
    "\n",
    "In addition, we'll set up this notebook's graphing displays and create global variables for global things, such as American English, `en_nlp`; and a grammar derived from the Penn Treebank, which, when we need it, will be initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "from math import sqrt, log\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk import Tree, Production, Nonterminal, CFG, ChartParser\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "import textacy\n",
    "import pyphen  # hyphenation library\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import matrix, corrcoef\n",
    "\n",
    "# make inline figures large\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (10, 10) # set this to (8, 8) for smaller output\n",
    "    \n",
    "pyphen.language_fallback('en_US')\n",
    "dic = pyphen.Pyphen(lang='en_US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll do is pull in our corpus. The corpus needs to contain a variety of reading levels within it.\n",
    "\n",
    "Additionally, we need to have an already-parse corpus. We can use the Penn Treebank for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Parse Trees\n",
    "\n",
    "Most of the time we're able to use `nltk.word_tokenize` and `nltk.pos_tag` to quickly get a tagging for a sentence.\n",
    "\n",
    "Sometimes we'll need to get back the original sentence from a parse tree when we don't have the original handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_sentence(sentence):\n",
    "    \"\"\"A helper method to easily tokenize a sentence\"\"\"\n",
    "    return nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "\n",
    "def tag_sentences(sentences):\n",
    "    \"\"\"A helper method to easily tokenize sentences\"\"\"\n",
    "    return [tag_sentence(sent) for sent in nltk.sent_tokenize(sentences)]\n",
    "\n",
    "def untag_sentence(tagged_sentence):\n",
    "    \"\"\"Get back the original text of a sentence.\"\"\"\n",
    "    leading_tags = set(['(', '$', '``'])  # don't need a space after, but do before\n",
    "    following_tags = set([')', ',', '.', ':', \"''\", 'POS'])  # need a space after, but not before\n",
    "    sentence = ''\n",
    "    no_sp = False\n",
    "    for w, pos in tagged_sentence:\n",
    "        if pos != '-NONE-':\n",
    "            if pos in following_tags or w in {'%'}:\n",
    "                sentence += w\n",
    "            else:\n",
    "                sentence += ('' if no_sp else ' ') + w\n",
    "            no_sp = pos in leading_tags\n",
    "    return sentence[1:]  # ignore leading space\n",
    "\n",
    "def untag_sentences(tagged_sentences):\n",
    "    \"\"\"Get back the original text of sentences.\"\"\"\n",
    "    return [untag_sentence(tagged_sentence) for tagged_sentence in tagged_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj = nltk.corpus.treebank.parsed_sents('wsj_0012.mrg')\n",
    "untag_sentences([tree.pos() for tree in wsj])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's begin to create our parsing functions. These are going to start simply, and get more complicated.\n",
    "\n",
    "## Textual metrics\n",
    "\n",
    "Let's begin with text-based metrics: sentence length and syllabification. We'll use the syllabification library `pyphen` to count the syllables in each word.\n",
    "\n",
    "We can build from these to create the standard text-based metrics, such as SMOG, Flesch-Kincaid, etc.\n",
    "\n",
    "Also note that every one of these takes a POS-tagged sentence, such as in the Treebank corpus, arranged as a list of (word/punctuation, POS) tuples. They do not take text, so it's important, if you want to use these on text, to tag the text beforehand. This can be done with, e.g., spaCy:\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "en_nlp = spacy.load('en')\n",
    "doc = en_nlp(u'One morning, when Gregor Samsa woke from troubled dreams, \\\n",
    "he found himself transformed in his bed into a horrible vermin. He lay on \\\n",
    "his armour-like back, and if he lifted his head a little he could see his \\\n",
    "brown belly, slightly domed and divided by arches into stiff sections.')\n",
    "[[(word.text, word.tag_) for word in sent] for sent in doc.sents]\n",
    "# returns [[('One', 'CD'), ('morning', 'NN'), (',', ','), ('when', 'WRB'), ...], ...]\n",
    "```\n",
    "\n",
    "or with the aforementioned `nltk.pos_tag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextStats:\n",
    "    \"\"\"\n",
    "    Determines basic text statistics, such as word length, syllabification,\n",
    "    etc. Additionally, computes several standard measures of readability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, corpus):\n",
    "        global dic\n",
    "        punct_tags = set(['(', ')', ',', '--', '.', ':',\n",
    "                          '-NONE-', '``', \"''\", '$'])\n",
    "\n",
    "        if not dic:\n",
    "            pyphen.language_fallback('en_US')\n",
    "            dic = pyphen.Pyphen(lang='en_US')\n",
    "        \n",
    "        f = open('dale-chall.txt')\n",
    "        dale_long_list = [word.lower() for word in f.read().split()]\n",
    "        f.close()\n",
    "\n",
    "        # The corpus is a tagged sentence or list of tagged sentences\n",
    "        self.corpus = [corpus] if isinstance(corpus[0], tuple) else corpus\n",
    "        self.depunctuated = [[(word, tag) for word, tag in sentence\n",
    "                              if tag not in punct_tags]\n",
    "                             for sentence in self.corpus]\n",
    "        self.stats = []\n",
    "        for sentence in self.depunctuated:\n",
    "            n = max(len(sentence), 1)\n",
    "            word_lengths = [len(word) for word, tag in sentence]\n",
    "            syllables = [len(dic.positions(word)) + 1\n",
    "                                   for word, tag in sentence]\n",
    "            self.stats.append({\n",
    "                'n_words': n,\n",
    "                'n_chars': sum(word_lengths),\n",
    "                'avg_word_length': sum(word_lengths) / n,\n",
    "                'n_syllables': sum(syllables),\n",
    "                'monosyllable_words': sum(s == 1 for s in syllables),\n",
    "                'polysyllable_words': sum(s >= 3 for s in syllables),\n",
    "                'n_long': sum(1 for word, POS in sentence\n",
    "                              if word.lower() in dale_long_list),\n",
    "            })\n",
    "\n",
    "    def get_stats(self):\n",
    "        n_s = len(self.corpus)\n",
    "\n",
    "        return {\n",
    "            'n_sentences': n_s,\n",
    "            'n_words': sum(stat['n_words'] for stat in self.stats),\n",
    "            'n_chars': sum(stat['n_chars'] for stat in self.stats),\n",
    "            'n_syllables': sum(stat['n_syllables'] for stat in self.stats),\n",
    "            'n_monosyllable_words': sum(stat['monosyllable_words'] for stat in self.stats),\n",
    "            'n_polysyllable_words': sum(stat['polysyllable_words'] for stat in self.stats),\n",
    "            'n_long': sum(stat['n_long'] for stat in self.stats),\n",
    "\n",
    "        }\n",
    "\n",
    "    def readabilities(self):\n",
    "        return {\n",
    "            'SMOG': self.SMOG(),\n",
    "            'flesch_kincaid_grade_level': self.flesch_kincaid_grade_level(),\n",
    "            'dale_chall': self.dale_chall(),\n",
    "        }\n",
    "\n",
    "    def SMOG(self):\n",
    "        \"\"\"\n",
    "        Computes the SMOG score of a piece of text, in this case, a list of\n",
    "        tagged sentences. There should be at least 30 sentences in the text.\n",
    "\n",
    "        McLaughlin, G. Harry (May 1969). \"SMOG Grading — a New Readability\n",
    "        Formula\" (PDF). Journal of Reading. 12 (8): 639–646.\n",
    "        \"\"\"\n",
    "        n_sentences = len(self.corpus)\n",
    "        n_polysyllables = sum(stat['polysyllable_words'] for stat in self.stats)\n",
    "        return 1.0430 * sqrt(n_polysyllables * (30 / n_sentences)) + 3.1291\n",
    "\n",
    "    def flesch_kincaid_grade_level(self):\n",
    "        \"\"\"\n",
    "        Computes the Flesch-Kincaid grade level of a piece of text, in this case,\n",
    "        a list of tagged sentences.\n",
    "\n",
    "        Kincaid JP, Fishburne RP Jr, Rogers RL, Chissom BS (February 1975).\n",
    "        \"Derivation of new readability formulas (Automated Readability Index,\n",
    "        Fog Count and Flesch Reading Ease Formula) for Navy enlisted personnel\".\n",
    "        Research Branch Report 8-75, Millington, TN: Naval Technical Training,\n",
    "        U. S. Naval Air Station, Memphis, TN.\n",
    "        \"\"\"\n",
    "        n_sentences = len(self.corpus)\n",
    "        n_words = sum(stat['n_words'] for stat in self.stats)\n",
    "        n_syllables = sum(stat['n_syllables'] for stat in self.stats)\n",
    "        return 0.39 * (n_words / n_sentences) + 11.8 * (n_syllables / n_words) - 15.59\n",
    "\n",
    "    def dale_chall(self):\n",
    "        \"\"\"\n",
    "        Computes the Dale-Chall Formula for readability, 1961 revision, for a\n",
    "        list of tagged sentences.\n",
    "\n",
    "        McCallum, D. and Peterson, J. (1982), Computer-Based Readability\n",
    "        Indexes, Proceedings of the ACM '82 Conference, (October 1982), 44-48.\n",
    "        \"\"\"\n",
    "        f = open('dale-chall.txt')\n",
    "        dale_long_list = [word.lower() for word in f.read().split()]\n",
    "        f.close()\n",
    "\n",
    "        n_dale_long = sum(1 for sentence in self.depunctuated\n",
    "                          for word, POS in sentence\n",
    "                          if word.lower() in dale_long_list)\n",
    "        \n",
    "        n_sentences = len(self.corpus)\n",
    "        n_words = sum(stat['n_words'] for stat in self.stats)\n",
    "\n",
    "        grade = 14.863 - 11.42 * (n_dale_long / n_words) + \\\n",
    "            0.0512 * (n_words / n_sentences)\n",
    "        return grade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wsj_pos = [tree.pos() for tree in wsj]\n",
    "wsj_text_stats = TextStats(wsj_pos)\n",
    "print(wsj_text_stats.get_stats())\n",
    "print(wsj_text_stats.readabilities())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the output of the textacy library — it's close. Arguably, in these small examples, my code handles punctuation more appropriately than textacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\\n'.join(untag_sentences(wsj_pos))\n",
    "doc = textacy.Doc(text)\n",
    "\n",
    "# t_words = list(textacy.text_stats.extract.words(doc, filter_punct=True, filter_stops=False, filter_nums=False))\n",
    "# my_words = (word for sentence in wsj_pos for word, pos in depunctuate(sentence))\n",
    "# print(list(zip(t_words, my_words)))\n",
    "# print('*' * 80)\n",
    "\n",
    "ts = textacy.text_stats.TextStats(doc)\n",
    "print('textacy stats:', ts.basic_counts)\n",
    "print('my stats:', wsj_text_stats.basic_counts())\n",
    "print('*' * 80)\n",
    "print('textacy stats:', ts.readability_stats)\n",
    "print('my stats:', wsj_text_stats.get_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next round of text analysis functions, let's dig a little deeper into the POS analysis. Remember that this is still sans parse-tree-ification.\n",
    "\n",
    "## Tag-based Metrics\n",
    "\n",
    "These use the POS tags. Since we're using the Penn Treebank, we need to make sure that whatever tags we're using are within this tagset; some tagged texts from the Brown Corpus, for example, use other tagsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TagStats:\n",
    "    \"\"\"\n",
    "    Determines tag-based statistics, such as POS counts, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, corpus):\n",
    "        def n_repeated_possessives(tagged_sentence):\n",
    "            \"\"\"\n",
    "            The number of 2+ repeated possessives, e.g.:\n",
    "            \"John's mother's neighbor's uncle's dog's Instagram account\" -> 5\n",
    "            \"John's dog's Instagram account\" -> 2\n",
    "            \"John's Instagram account\" -> 0  # because it's not repeated\n",
    "            \"\"\"\n",
    "            max_count = 0\n",
    "\n",
    "            count, loc = 0, -1\n",
    "            for i, (word, pos) in enumerate(tagged_sentence[::2]):\n",
    "                if pos == 'POS':\n",
    "                    count = count + 1 if (loc == i - 1) else 1\n",
    "                    max_count = max(max_count, count)\n",
    "                    loc = i\n",
    "\n",
    "            count, loc = 0, -1\n",
    "            for i, (word, pos) in enumerate(tagged_sentence[1::2]):\n",
    "                if pos == 'POS':\n",
    "                    count = count + 1 if (loc == i - 1) else 1\n",
    "                    max_count = max(max_count, count)\n",
    "                    loc = i\n",
    "\n",
    "            return max_count if max_count >= 2 else 0\n",
    "\n",
    "        def n_repeated_adverbs(tagged_sentence):\n",
    "            \"\"\"\n",
    "            The number of 2+ repeated adverbs (RB, RBR, and RBS/RBT) e.g.:\n",
    "            \"harder better faster stronger\" -> 4  # as adverbs, not adjectives!\n",
    "            \"most happily\" -> 2\n",
    "            \"likely ready\" -> 0  # because \"ready\" is an adjective\n",
    "            \"\"\"\n",
    "            adverbs = {'RB', 'RBR', 'RBS', 'RBT', 'RB$',\n",
    "                       'RB+BEZ', 'RB+CS', 'RBR+CS', 'RN', 'RP'}\n",
    "            max_count = 0\n",
    "            count, loc = 0, -1\n",
    "            for i, (word, pos) in enumerate(tagged_sentence):\n",
    "                if pos in adverbs:\n",
    "                    count = count + 1 if (loc == i - 1) else 1\n",
    "                    max_count = max(max_count, count)\n",
    "                    loc = i\n",
    "\n",
    "            return max_count if max_count >= 2 else 0\n",
    "\n",
    "        # the corpus is a tagged sentence or list of tagged sentences\n",
    "        self.corpus = [corpus] if isinstance(corpus[0], tuple) else corpus\n",
    "        self.stats = []\n",
    "        \n",
    "        for sentence in self.corpus:\n",
    "            self.stats.append({\n",
    "                'n_POSs': len(set(pos for word, pos in sentence)),\n",
    "                'n_pronouns': len([pos for word, pos in sentence if pos == 'PRP']),\n",
    "                'n_repeated_possessives': n_repeated_possessives(sentence),\n",
    "                'n_repeated_adverbs': n_repeated_adverbs(sentence),       \n",
    "            })\n",
    "                                   \n",
    "        self.POSs = [set(pos for word, pos in sentence) for sentence in self.corpus]\n",
    "\n",
    "    def get_stats(self):\n",
    "        \"\"\"Combine all the statistics together\"\"\"\n",
    "        ...\n",
    "        n = len(self.stats)\n",
    "        return {\n",
    "            'total_POSs': len({POS for POSs in self.POSs for POS in POSs}),\n",
    "            'avg_POSs': sum(stat['n_POSs'] for stat in self.stats) / n,\n",
    "            'avg_pronouns': sum(stat['n_pronouns'] for stat in self.stats) / n,\n",
    "            'avg_repeated_possessives': sum(stat['n_repeated_possessives'] for stat in self.stats) / n,\n",
    "            'avg_repeated_adverbs': sum(stat['n_repeated_adverbs'] for stat in self.stats) / n,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('WSJ stats:', TagStats(wsj_pos).get_stats())\n",
    "\n",
    "r_p_sent = [('My', 'PRP$'), ('dog', 'NN'), (\"'s\", 'POS'), ('therapist', 'NN'), (\"'s\", 'POS'),\n",
    "            ('uncle', 'NN'), (\"'s\", 'POS'), ('friend', 'NN'), (\"'s\", 'VBZ'), ('smiling', 'VBG')]\n",
    "\n",
    "r_a_sent = [('My', 'PRP$'), ('very', 'RB'), ('very', 'RB'), ('very', 'RB'), ('very', 'RB'), ('good', 'JJ'),\n",
    "            ('dog', 'NN')]\n",
    "\n",
    "print(TagStats(r_p_sent).get_stats())  # should be 3, not 4\n",
    "print(TagStats(r_a_sent).get_stats())  # should be 4\n",
    "print(TagStats(wsj_pos).stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based Metrics\n",
    "\n",
    "These use the structure of the parse trees, _and_ the productions to measure things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeStats:\n",
    "    \"\"\"\n",
    "    Determine tree-based statistics, such as tree depths, production counts,\n",
    "    etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, corpus):\n",
    "        \"\"\"\n",
    "        We'll use the Stanford Parser to do the heavy lifting here.\n",
    "        \"\"\"\n",
    "        def n_productions(parse_tree, production):\n",
    "            \"\"\"\n",
    "            Returns the number of productions of type `production` in\n",
    "            parse_tree.\n",
    "            \"\"\"\n",
    "            productions = list(parse_tree.subtrees(\n",
    "                filter=lambda t: t.label() == production))\n",
    "            return len(productions)\n",
    "\n",
    "        jar = '/usr/local/Cellar/stanford-parser/3.6.0/libexec/stanford-parser.jar'\n",
    "        model = '/usr/local/Cellar/stanford-parser/3.6.0/libexec/stanford-parser-3.6.0-models.jar'\n",
    "        self.corpus = [corpus] if isinstance(corpus[0], tuple) else corpus\n",
    "        self.parser = StanfordParser(path_to_jar=jar, path_to_models_jar=model)\n",
    "        self.stats = []\n",
    "\n",
    "        parsed_sents = self.parser.tagged_parse_sents(self.corpus)\n",
    "        self.trees = [t for tree in parsed_sents for t in tree]\n",
    "            \n",
    "        for tree in self.trees:\n",
    "            self.stats.append({\n",
    "                'depth': tree.height(),\n",
    "                'noun_phrases': n_productions(tree, 'NP'),\n",
    "                'prepositional_phrases': n_productions(tree, 'PP'),\n",
    "                'sbars': n_productions(tree, 'SBAR'),\n",
    "                'nonterminals': len(tree.productions()),\n",
    "            })\n",
    "\n",
    "\n",
    "    def get_stats(self):\n",
    "        \"\"\"\n",
    "        Combines all the statistics together\n",
    "        \"\"\"            \n",
    "        n = len(self.stats)\n",
    "        max_tree_depth = max(stat['depth'] for stat in self.stats)\n",
    "        avg_tree_depth = sum(stat['depth'] for stat in self.stats) / n\n",
    "        avg_noun_phrases = sum(stat['noun_phrases'] for stat in self.stats) / n\n",
    "        avg_prep_phrases = sum(stat['prepositional_phrases'] for stat in self.stats) / n\n",
    "        avg_sbars = sum(stat['sbars'] for stat in self.stats) / n\n",
    "        avg_nonterminals = sum(stat['nonterminals'] for stat in self.stats) / n\n",
    "        \n",
    "        return {\n",
    "            'max_tree_depth': max_tree_depth,\n",
    "            'avg_tree_depth': avg_tree_depth,\n",
    "            'avg_noun_phrases': avg_noun_phrases,\n",
    "            'avg_prepositional_phrases': avg_prep_phrases,\n",
    "            'avg_sbars': avg_sbars,\n",
    "            'avg_nonterminals': avg_nonterminals,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test stats class\n",
    "tagged_sentences = tag_sentences('The quick brown fox jumps over the lazy dog. ' +\n",
    "                                 'Now is the time for all good men to come to the aid of their party.')\n",
    "\n",
    "tree_stats = TreeStats(tagged_sentences)\n",
    "tree_stats.get_stats()\n",
    "print(tree_stats.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ptr(text_stats, tag_stats, tree_stats):\n",
    "    \"\"\"\n",
    "    From the textual, tag-based, and tree-based statistics, create a\n",
    "    parse tree readability measurement.\n",
    "    \"\"\"\n",
    "    stats = [{pair for d in L for pair in d.items()}\n",
    "             for L in zip(text_stats, tag_stats, tree_stats)]\n",
    "\n",
    "    text_complexity = [15 +\n",
    "                       10 * (stats['polysyllable_words'] / stats['n_words']) -\n",
    "                       15 * (stats['n_long'] / stats['n_words'])\n",
    "                       for stats in all_stats]\n",
    "    tag_complexity = [stats['n_POSs'] / (stats['n_words'] -\n",
    "                                         stats['n_repeated_adverbs'] -\n",
    "                                         stats['n_repeated_possessives'])\n",
    "                      for stats in all_stats]\n",
    "    tree_complexity = [1.7 * (stats['prepositional_phrases'] +\n",
    "                              stats['noun_phrases']) / stats['depth'] +\n",
    "                       0.7 * stats['depth']\n",
    "                       for stats in all_stats]\n",
    "    ptr_per_sent = [0.4 * text + tag + 0.6 * tree\n",
    "                    for text, tag, tree in\n",
    "                    zip(text_complexity, tag_complexity, tree_complexity)]\n",
    "\n",
    "    return sum(ptr_per_sent) / len(ptr_per_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr(text_stats, tag_stats, tree_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOG(sentence):\n",
    "    \"\"\"\n",
    "    Computes the SMOG score of a piece of text, in this case, a list of\n",
    "    tagged sentences. There should be at least 30 sentences in the text.\n",
    "\n",
    "    McLaughlin, G. Harry (May 1969). \"SMOG Grading — a New Readability\n",
    "    Formula\" (PDF). Journal of Reading. 12 (8): 639–646.\n",
    "    \"\"\"\n",
    "    return 1.0430 * sqrt(sentence['polysyllable_words'] * 30) + 3.1291\n",
    "\n",
    "def flesch_kincaid_grade_level(sentence):\n",
    "    \"\"\"\n",
    "    Computes the Flesch-Kincaid grade level of a piece of text, in this case,\n",
    "    a list of tagged sentences.\n",
    "\n",
    "    Kincaid JP, Fishburne RP Jr, Rogers RL, Chissom BS (February 1975).\n",
    "    \"Derivation of new readability formulas (Automated Readability Index,\n",
    "    Fog Count and Flesch Reading Ease Formula) for Navy enlisted personnel\".\n",
    "    Research Branch Report 8-75, Millington, TN: Naval Technical Training,\n",
    "    U. S. Naval Air Station, Memphis, TN.\n",
    "    \"\"\"\n",
    "    n_words = sentence['n_words']\n",
    "    n_syllables = sentence['n_syllables']\n",
    "    return 0.39 * n_words + 11.8 * n_syllables/n_words - 15.59\n",
    "\n",
    "def dale_chall(sentence):\n",
    "    \"\"\"\n",
    "    Computes the Dale-Chall Formula for readability, 1961 revision, for a\n",
    "    list of tagged sentences.\n",
    "\n",
    "    McCallum, D. and Peterson, J. (1982), Computer-Based Readability\n",
    "    Indexes, Proceedings of the ACM '82 Conference, (October 1982), 44-48.\n",
    "    \"\"\"\n",
    "    n_long = sentence['n_long']\n",
    "    n_words = sentence['n_words']\n",
    "\n",
    "    return 14.863 - 11.42 * (n_long / n_words) + 0.0512 * n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smog = [metric['SMOG'] for metric in metrics]\n",
    "dale_chall = [metric['dale_chall'] for metric in metrics]\n",
    "\n",
    "n_words = [stats['n_words'] for stats in all_stats]\n",
    "plt.scatter(n_words, smog)\n",
    "plt.scatter(n_words, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_long = [stats['n_long'] for stats in all_stats]\n",
    "plt.scatter(n_long, smog)\n",
    "plt.scatter(n_long, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_long = [stats['n_long'] / max(stats['n_words'], 1) for stats in all_stats]\n",
    "plt.scatter(n_long, smog)\n",
    "plt.scatter(n_long, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [stats['depth'] for stats in all_stats]\n",
    "plt.scatter(d, smog)\n",
    "plt.scatter(d, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['nonterminals'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['n_long'] / max(stats['nonterminals'], 1) for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['noun_phrases'] + stats['prepositional_phrases'] + 3 * stats['n_repeated_adverbs'] + 2 * stats['n_repeated_possessives'] - stats['n_POSs'] / stats['n_words'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['prepositional_phrases'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [ stats['nonterminals'] / stats['depth'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [ stats['n_words'] / stats['nonterminals'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [ stats['n_repeated_adverbs'] + stats['n_repeated_possessives'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['noun_phrases'] + stats['prepositional_phrases'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['noun_phrases'] / max(stats['prepositional_phrases'], 1) for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['n_POSs'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['n_syllables'] / sqrt(max(stats['n_long'], 1)) for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [(stats['nonterminals'] / stats['n_words'])**2 * stats['n_syllables'] / sqrt(max(stats['n_long'], 1))**2 for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['n_words']  / stats['n_syllables'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = [stats['nonterminals'] - stats['noun_phrases'] - stats['prepositional_phrases'] for stats in all_stats]\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word length\n",
    "n_g = [15 + 10 * (stats['polysyllable_words'] / stats['n_words']) - 15 * (stats['n_long'] / stats['n_words']) for stats in all_stats]\n",
    "plt.scatter(n_g, smog)\n",
    "plt.scatter(n_g, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence complexity\n",
    "n_t = [stats['n_words'] / stats['depth'] for stats in all_stats]\n",
    "plt.axis\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence complexity\n",
    "n_t = [2 * stats['n_words'] / stats['depth'] for stats in all_stats]\n",
    "plt.axis\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence complexity\n",
    "n_t = [20 * stats['n_words'] / max(stats['noun_phrases'],1) for stats in all_stats]\n",
    "plt.axis\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag complexity\n",
    "n_t = [80 - 30 * stats['n_POSs'] / max(stats['n_words'],1) for stats in all_stats]\n",
    "plt.axis\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag complexity\n",
    "n_t = [1.7 * (stats['prepositional_phrases'] + stats['noun_phrases']) / stats['depth'] + 0.7 * stats['depth'] for stats in all_stats]\n",
    "# n_g = [0.07* stats['depth'] for stats in all_stats]\n",
    "plt.axis\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag complexity\n",
    "n_t = [ stats['n_POSs'] / (stats['n_words'] - stats['n_repeated_adverbs'] - stats['n_repeated_possessives']) for stats in all_stats]\n",
    "# n_t = [stats['noun_phrases'] - max(stats['n_pronouns'],1) for stats in all_stats]\n",
    "plt.axis\n",
    "plt.scatter(n_t, smog)\n",
    "plt.scatter(n_t, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_complexity = [15 + 10 * (stats['polysyllable_words'] / stats['n_words']) - 15 * (stats['n_long'] / stats['n_words']) for stats in all_stats]\n",
    "tag_complexity = [ stats['n_POSs'] / (stats['n_words'] - stats['n_repeated_adverbs'] - stats['n_repeated_possessives']) for stats in all_stats]\n",
    "tree_complexity = [1.7 * (stats['prepositional_phrases'] + stats['noun_phrases']) / stats['depth'] + 0.7 * stats['depth'] for stats in all_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr = [0.4 * text + tag + 0.6 * tree for text, tag, tree in zip(text_complexity, tag_complexity, tree_complexity)]\n",
    "plt.axis\n",
    "plt.scatter(ptr, smog)\n",
    "plt.scatter(ptr, dale_chall,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrcoef(ptr, dale_chall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrcoef(ptr, smog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
